# Server Configuration
PORT=5000
NODE_ENV=development

# LLM Configuration
# For local Ollama (LLaMA / Mistral)
OLLAMA_URL=http://localhost:11434
LLM_MODEL=mistral

# Alternative: OpenAI API (fallback)
OPENAI_API_KEY=your_openai_api_key_here

# Docling Configuration (optional - for resume parsing)
ENABLE_DOCLING=false
DOCLING_URL=http://localhost:5001

# JWT Secret (for production auth)
JWT_SECRET=your_super_secret_jwt_key_here
